---
permalink: /
title: "Deep Learning course - Master in Artificial Intelligence - Universitat Polit√®cnica de Catalunya and Barcelona Supercomputing Center"
excerpt: "About me"
author_profile: false
redirect_from:
  - /about/
    - /about.html
---

The Table of Contents:

- [About](#about)
- [Lecturers](#lecturers)
- [Course Structure](#structure)
    - [Theory](#theory)
    - [Guided Laboratory](#guided)
    - [Autonomous Laboratory](#autonomous)
- [Course Evaluation](#evaluation)
- [Lessons](#lessons)
    - [#1 Feedforward Nets and Conv Nets](#mlp_convnets)
    - [#2 Recurrent Neural Nets](#rnn_nets)
    - [#3 Embedding spaces](#embeddings)
    - [#4 High Performance Computing Aspects of Deep Learning](#HPC) 
- [Code and Lab Resources](#code)
- [Papers of interest](#papers)


<a name='about'></a>
### About
This is the official web page for the contents of the lectures from the Deep Learning course, at the Master in Artificial Intelligence from UPC. Here you can find basic information as well as everything needed to follow the course.


<a name='lecturers'></a>
### Lecturers
- Dario Garcia-Gasulla (Coordinator) (BSC, dario.garcia@bsc.es)
- Marc Casas (BSC, marc.casas@bsc.es)
- Javier Bejar (UPC-CS, bejar@cs.upc.edu)



<a name='structure'></a>
### Course Structure

This course provides an applied approach to Deep Learning. The course is structured in 4 thematic blocks, and each block as 3 parts: theory, guided laboratory and autonomous laboratory.

<a name='theory'></a>
#### Theory

The theory part of a block provides a review of the basic concepts of Deep Learning, but is intended only as an introduction. Multiple references are given in the theory section, and the interested student should read further from those references to learn more details of the introduced topics. Beyond the cited works, there are lots of materials online of Deep Learning, although it is recommended to read more than one source, as many sources explain only one aspect or interpretation of a certain topic. A good reference for most topics is the "Deep Learning Book" by Ian Goodfellow and Yoshua Bengio and Aaron Courville. There is a physical copy of the book in the UPC library, and it can also be found online.


<a name='guided'></a>
#### Guided Laboratory

The guided laboratory provides working code that can serve as a starting point for students. These codes are commented, and show a variety of algorithmic solutions. The guided laboratory will be reviewed and discussed in class with students.

<a name='autonomous'></a>
#### Autonomous Laboratory

The autonomous laboratory session is intended for students to experiment with Deep Learning methods, and draw their own conclusions. On each autonomous laboratory, a set of example experiments will be detailed, but students are strongly encouraged to define their own experiments based on their own curiosity.

<a name='evaluation'></a>
### Course Evaluation

The course is evaluated 50% by theory comprehension and 50% by experimental work. Theory comprehension is measured by an analysis on a paper chosen by the student. The student should read and fully understand the paper, reading as many references as needed for that purpose. A presentation will be done where the student will describe the paper itself, and provide constructive criticism on it. This may include, but is not limited to, answers to questions such as:

- What is the main contribution of the article?
- How could this paper be extended by more experiments or analysis?
- Are there flaws in the paper methodology?
- What future work can derive from this paper?

The experimental evaluation will be based on reports written by the student for each thematic block, illustrating the conclusions derived from the autonomous laboratory sessions. Each thematic block will provide a list of analysis suggested to students. Alternative experimental reports suggested by the student are also acceptable, previous validation from the lecturers (e.g., replicating a particular paper results, or evaluating a different approach than the one suggested by the lecturers).



<a name='lessons'></a>
### Lessons

<a name='mlp_convnets'></a>
#### Lesson 1
Feedforward Nets and Conv Nets (lecturer: Dario Garcia)
- [Theory](mlp-convnets-theory/)
- [Lab guided](mlp-convnets-lab-guided/)
- [Lab autonomous](mlp-convnets-lab-autonomous/)


<a name='rnn_nets'></a>
#### Lesson 2
Recurrent Neural Networks (lecturer: Javier Bejar)

- [Theory](rnn-theory)
- [Lab guided](rnn-lab-guided)
- [Lab autonomous](rnn-lab-autonomous)


<a name='embeddings'></a>
#### Lesson 3
Embedding spaces (lecturer: Dario Garcia)

- [Theory](emb-space-theory)
- [Lab guided](embedding-spaces-lab-guided)
- [Lab autonomous]

<a name='HPC'></a>
#### Lesson 4
High Performance Computing Aspects of Deep Learning (lecturer: Marc Casas)
- [Theory](https://www.bsc.es/sites/default/files/public/bscw2/user/user-attachments/dlcourse_hpcfordl.pdf)
- Lab Guided
- Lab Autonomius

<a name='code'></a>
### Code and Lab Resources

The codes used in the lab sessions can be downloaded from the following locations:
- [Lesson 1: Feedforward Neural Nets and Conv Nets](https://github.com/UPC-MAI-DL/UPC-MAI-DL.github.io/tree/master/_codes/1.FNN-CNN)
- [Lesson 2: Recurrent Neural Networks](https://github.com/UPC-MAI-DL/UPC-MAI-DL.github.io/tree/master/_codes/2.RNN)



<a name='papers'></a>
### Papers of Interest

For the evaluation of the theoretical aspects of the course, we offer a list of papers of interest which the student may chose to read and review. These are loosely categorized.

[Papers of interests](papers-of-interest/)
